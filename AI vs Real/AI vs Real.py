# -*- coding: utf-8 -*-
"""AiVsReal.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p30bsEO5IIAKeUtrZ6SXA5Cd5xvygHWh
"""

!pip install -q kaggle
from google.colab import files
files.upload()

!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle/

!chmod 600 ~/.kaggle/kaggle.json

!kaggle competitions download -c induction-task

!unzip induction-task.zip

!pip install keras_preprocessing

from keras.utils import to_categorical
from keras_preprocessing.image import load_img
from keras.models import Sequential
from keras.applications import MobileNetV2, ResNet152, VGG16, EfficientNetB0, InceptionV3
from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D
from keras.regularizers import l2
import os
from sklearn.preprocessing import LabelEncoder
import pandas as pd
import numpy as np
from tqdm.notebook import tqdm
from sklearn.model_selection import train_test_split

def createdataframe(dir):
    image_paths = []
    labels = []
    for label in os.listdir(dir):
        for imagename in os.listdir(os.path.join(dir, label)):
            image_paths.append(os.path.join(dir, label, imagename))
            labels.append(label)
        print(label, "completed")
    return image_paths, labels

def extract_features(images):
    features = []
    for image in tqdm(images):
        img = load_img(image, target_size=(236, 236))
        img = np.array(img)
        features.append(img)
    features = np.array(features)
    features = features.reshape(features.shape[0], 236, 236, 3)
    return features

TRAIN_DIR = "/content/Data/Train"

train = pd.DataFrame()
train['image'], train['label'] = createdataframe(TRAIN_DIR)

train_features = extract_features(train['image'])

x_train = train_features / 255.0

le = LabelEncoder()
le.fit(train['label'])
y_train = le.transform(train['label'])
y_train = to_categorical(y_train, num_classes=2)

x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)

model = Sequential()


model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=(236, 236, 3),
                 kernel_regularizer=l2(0.01)))
model.add(MaxPooling2D())

model.add(Conv2D(32, kernel_size=(3, 3), activation='relu',
                 kernel_regularizer=l2(0.01)))
model.add(MaxPooling2D())

model.add(Conv2D(64, kernel_size=(3, 3), activation='relu',
                 kernel_regularizer=l2(0.01)))
model.add(MaxPooling2D())

model.add(Flatten())
model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.01)))
model.add(Dropout(0.3))
model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.01)))
model.add(Dropout(0.3))
model.add(Dense(2, activation='softmax'))

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
history = model.fit(x=x_train, y=y_train, validation_data=(x_val, y_val), batch_size=16, epochs=10)

import matplotlib.pyplot as plt
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper right')
plt.show()

#delete image_62

import shutil

dir_to_remove = "/content/Data/Test/.ipynb_checkpoints"

try:
    shutil.rmtree(dir_to_remove)
    print(f"Directory '{dir_to_remove}' and its contents removed successfully.")
except FileNotFoundError:
    print(f"Directory '{dir_to_remove}' not found.")
except OSError as e:
    print(f"Error removing directory '{dir_to_remove}': {e}")

TEST_DIR = "/content/Data/Test"

def create_test_dataframe(dir):
    image_paths = []
    for imagename in os.listdir(dir):
        image_paths.append(os.path.join(dir, imagename))
    return image_paths

def extract_features_test(images):
    features = []
    for image in tqdm(images):
        img = load_img(image, target_size=(236, 236))
        img = np.array(img)
        features.append(img)
    features = np.array(features)
    features = features.reshape(len(features), 236, 236, 3)
    return features

test = pd.DataFrame()
test['image'] = create_test_dataframe(TEST_DIR)
test_features = extract_features_test(test['image'])
x_test = test_features / 255.0

predictions = model.predict(x_test)
predicted_labels = np.argmax(predictions, axis=1)
predicted_labels = le.inverse_transform(predicted_labels)

image_ids = [img.split('/')[-1] for img in test['image']]

results = pd.DataFrame({'Id': image_ids, 'Label': predicted_labels})
results.to_csv('submission.csv', index=False)

model.save('my_model.h5')

from google.colab import files
files.download('my_model.h5')

!kaggle competitions download -c induction-task-2025

!unzip -o induction-task-2025.zip

TEST_DIR = "/content/Test_Images"

test = pd.DataFrame()
test['image'] = create_test_dataframe(TEST_DIR)
test_features = extract_features_test(test['image'])
x_test = test_features / 255.0

predictions = model.predict(x_test)
predicted_labels = np.argmax(predictions, axis=1)
predicted_labels = le.inverse_transform(predicted_labels)

image_ids = [img.split('/')[-1] for img in test['image']]

results = pd.DataFrame({'Id': image_ids, 'Label': predicted_labels})
results.to_csv('submission_2ndcompetition.csv', index=False)

